---
title: "Chapter 11, Vignette 1: ROC sample size from first principles"
author: "Dev P. Chakraborty"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{ROC sample size}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
library(RJafroc)
library(ggplot2)
```

## Introduction
The starting point is a pilot study. In this example the Van Dyke dataset is regarded as a pilot study. Two implementations are shown, a first principles implementation, which shows direct application of the relevant formulae in **Chapter 11**.  


## Illustrating the F-distribution

```{r, fig.align = "center"}
ndf <- 1;ddf <- 10;ncp <- c(0,2,5,10)
fCrit <- qf(0.95, ndf,ddf)
cat("critical value of x for rejecting NH is ", fCrit,"\n")
x <- seq(1, 20, 0.1)
myLabel <- c("A", "B", "C", "D")
myLabelIndx <- 1
for (i in 1:length(ncp))
{
  y <- df(x,ndf,ddf,ncp=ncp[i])
  cat("ndf = ", ndf, ", ddf = ", ddf, ", ncp = ", ncp[i], ", prob > fCrit = ", 
      1-pf(fCrit, ndf, ddf, ncp = ncp[i]), "\n")
  curveData <- data.frame(x = x, pdf = y)
  curvePlot <- ggplot(data = curveData, mapping = aes(x = x, y = pdf)) + 
    geom_line() +
    ggtitle(myLabel[myLabelIndx]);myLabelIndx <- myLabelIndx + 1
  print(curvePlot)
}
```             

### Comments

(A) Corresponds to `ncp = 0`, which yields the usual (aka *central*) F-distribution that was used in the previous two chapters (9 and 10). The integral under this distribution is unity (this is true for all plots above). The critical value, `fCrit` in the code, is that value of `x` such that the probability of exceeding `x` is $\alpha$; in the current example `fCrit` = `r qf(0.95, ndf,ddf)`. Notice the use of the quantile function `qf()` to determine this value, also that the default value of `ncp`, namely zero, is used; specifically, one does not pass a 4th argument to `qf()`. **The decision rule for rejecting the NH uses the NH distribution of the F-statistic**, i.e., reject the NH if F >= `fCrit`. As expected, `prob > fCrit` = `r 1-pf(fCrit, ndf, ddf, ncp = ncp[1])` because this is how `fCrit` was defined. 
(B) Corresponds to `ncp = 2`. It is noticeably shifted to the right as compared to A, thereby making it more likely that the observed value of the F-statistic will exceed the critical value determined for the NH distribution. In fact, `prob > fCrit` = `r 1-pf(fCrit, ndf, ddf, ncp = ncp[2])`, which is the *statistical power*. 
(C) Corresponds to `ncp = 5`, and now `prob > fCrit` = `r 1-pf(fCrit, ndf, ddf, ncp = ncp[3])`. 
(D) Corresponds to `ncp = 10`, and now `prob > fCrit` is  `r 1-pf(fCrit, ndf, ddf, ncp = ncp[4])`. 
The effect of the shift is obvious in plots (C) and (D). Considering a vertical line at `x = 4.10`, most of the distribution in plot (D), more than `r 1-pf(fCrit, ndf, ddf, ncp = ncp[4])`, to be precise, lies to the right of this line, so the NH is more than `r 1-pf(fCrit, ndf, ddf, ncp = ncp[4])` likely to be rejected. Of course, what causes the shift is the increased value of the non-centrality parameter. The larger that non-centrality parameter, the greater the shift to the right.

## Sample size estimation using the DBMH method

The Van Dyke dataset in file `VanDyke.lrc`, in `"MRMC"` format, is regarded as a pilot study. The command `rocData <- DfReadDataFile(fileName, format = "MRMC")` reads the data and saves it to a `dataset` object `rocData`. The next line uses the function `StSignificanceTesting()` to apply `"DBMH"` analysis using the `"Wilcoxon"` figure of merit. The next line extracts the needed variance components `varYTR`, `varYTC` and `varYEps` (the Y's denote pseudovalue based values). The next line extracts the effect size.

```{r}
alpha <- 0.05;cat("alpha = ", alpha, "\n")
fileName <- "VanDyke.lrc"
#fileName <- "Franken1.lrc"
rocData <- DfReadDataFile(fileName, format = "MRMC")
retDbm <- StSignificanceTesting(dataset = rocData, FOM = "Wilcoxon", method = "DBMH") 
varYTR <- retDbm$varComp$varComp[3];varYTC <- retDbm$varComp$varComp[4];varYEps <- retDbm$varComp$varComp[6]
effectSize <- retDbm$ciDiffTrtRRRC$Estimate
````
The observed effect size is `effectSize` = `R effectSize`

### Random reader random case (RRRC)
This illustrates random reader random case sample size estimation. Assumed are 10 readers and 163 cases: `J <- 10; K <- 163` in the pivotal study.  
```{r}
#RRRC
J <- 10; K <- 163 # in the pivotal study
ncp <- (0.5*J*K*(effectSize)^2)/(K*varYTR+max(J*varYTC,0)+varYEps)
MS <- UtilMeanSquares(rocData, FOM = "Wilcoxon", method = "DBMH")
ddf <- (MS$msTR+max(MS$msTC-MS$msTRC,0))^2/(MS$msTR^2)*(J-1)
FCrit <- qf(1 - alpha, 1, ddf)
Power <- 1-pf(FCrit, 1, ddf, ncp = ncp)
````

The next line calculates the non centrality parameter, `ncp` = `r ncp`. Note that `effectSize` enters as the **square**. Using the `UtilMeanSquares` function, the next line extracts the needed mean squares. The next line calculates `ddf` = `r ddf`. The remaining lines calculate the critical value of the F-distribution, `FCrit` = `r qf(1 - alpha, 1, ddf)` and the statistical power = `r Power`.

### Fixed reader random case (FRRC)

The following code illustrates fixed reader random case sample size estimation. Assumed are 10 readers and 133 cases: `J <- 10; K <- 133` in the pivotal study.  

```{r}
#FRRC
J <- 10; K <- 133 # in the pivotal study
ncp <- (0.5*J*K*(effectSize)^2)/(max(J*varYTC,0)+varYEps)
ddf <- (K-1)
FCrit <- qf(1 - alpha, 1, ddf)
Power <- 1-pf(FCrit, 1, ddf, ncp = ncp)
````
This time non centrality parameter, `ncp` = `r ncp`, `ddf` = `r ddf`, `FCrit` = `r qf(1 - alpha, 1, ddf)` and statistical power = `r Power`.

### Random reader fixed case (RRFC)
The following code illustrates random reader random case sample size estimation. Assumed are 10 readers and 53 cases: `J <- 10; K <- 5` in the pivotal study.
```{r}
#RRFC
J <- 10; K <- 53 # in the pivotal study
ncp <- (0.5*J*K*(effectSize)^2)/(K*varYTR+varYEps)
ddf <- (J-1)
FCrit <- qf(1 - alpha, 1, ddf)
Power <- 1-pf(FCrit, 1, ddf, ncp = ncp)
````

This time non centrality parameter, `ncp` = `r ncp`, `ddf` = `r ddf`, `FCrit` = `r qf(1 - alpha, 1, ddf)` and statistical power = `r Power`.

### Summary
For 10 readers, the numbers of cases needed for 80% power is largest (163) for RRRC and least for RRFC (53). For all three analyses, the expectation of 80% power is met. 


## RJafroc implementation of sample size, DBMH method

The relevant function is `SsPowerTable` called at the very end. The rest is extracting the variance components and calculating a realistic effect size. The listed power table shows combinations of readers and cases yielding the desired 80% power.
```{r}
fileName <- "VanDyke.lrc"
#fileName <- "Franken1.lrc"
BestCaseScenario <-  FALSE;alpha <- 0.05
rocData <- DfReadDataFile(fileName, format = "MRMC")
retDbm <- StSignificanceTesting(dataset = rocData, FOM = "Wilcoxon", method = "DBMH") 
varYTR <- retDbm$varComp$varComp[3];varYTC <- retDbm$varComp$varComp[4];varYEps <- retDbm$varComp$varComp[6]
effectSize <- retDbm$ciDiffTrtRRRC$Estimate
sigma <- (retDbm$ciDiffTrtRRRC$`CI Upper`-retDbm$ciDiffTrtRRRC$`CI Lower`)/4
if (BestCaseScenario == TRUE) {
  if (fileName == "VanDyke.lrc") {
    effectSize <- effectSize -2*sigma
  }
  if (fileName == "Franken1.lrc") {
    effectSize <- effectSize +2*sigma
  }
}
cat("p-value = ", retDbm$pRRRC, ", anticipated effectSize = ",
    effectSize, ", CI Lower =", retDbm$ciDiffTrtRRRC$`CI Lower`,
    ", CI Upper =", retDbm$ciDiffTrtRRRC$`CI Upper`, "\n")
powTab <- SsPowerTable(alpha = alpha, effectSize = effectSize, desiredPower = 0.8,  
                       method = "DBMH", option = "ALL", varYTR, varYTC, varYEps)
print(powTab)
````



## Sample size estimation using the ORH method

`KStar` is the number of cases in the pilot study.

```{r}
BestCaseScenario <-  FALSE;alpha <- 0.05
fileName <- "VanDyke.lrc"
#fileName <- "Franken1.lrc"
cat("File name = ", fileName, "\n")
rocData <- DfReadDataFile(fileName, format = "MRMC")
KStar <- length(rocData$NL[1,1,,1])
retORH <- StSignificanceTesting(dataset = rocData, FOM = "Wilcoxon", method = "ORH") 
Cov1 <- retORH$varComp$varCov[3]
Cov2 <- retORH$varComp$varCov[4]
Cov3 <- retORH$varComp$varCov[5]
Var <- retORH$varComp$varCov[6]
VarTR <- retORH$varComp$varCov[2]
VarTR <- max(VarTR,0)
effectSize <-retORH$ciDiffTrtRRRC$Estimate
sigma <- (retORH$ciDiffTrtRRRC$`CI Upper`-retORH$ciDiffTrtRRRC$`CI Lower`)/4
if (BestCaseScenario == TRUE) {
  if (fileName == "VanDyke.lrc") {
    effectSize <- effectSize -2*sigma
  }
  if (fileName == "Franken1.lrc") {
    effectSize <- effectSize +2*sigma
  }
}
cat("p-value = ", retORH$pRRRC, ", postulated effectSize = ",
    effectSize, ", CI Lower =", retORH$ciDiffTrtRRRC$`CI Lower`,
    ", CI Upper =", retORH$ciDiffTrtRRRC$`CI Upper`, "\n")
powTab <- SsPowerTable(alpha = alpha, effectSize = effectSize, desiredPower = 0.8,  
                       method = "ORH", option = "ALL", Cov1, Cov2, Cov3, VarTR, Var, KStar)
print(powTab)
````


